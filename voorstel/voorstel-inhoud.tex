%---------- Inleiding ---------------------------------------------------------

\section{Inleiding}%
\label{sec:inleiding}

Een ontwikkelingsteam heeft uiteenlopende verantwoordelijkheden. Naast hun kernactiviteit, het ontwikkelen van software, is het ook belangrijk dat zij ondersteuning bieden bij vragen en problemen van klanten. Deze vragen hebben vaak betrekking op fouten of problemen binnen de toepassing. In grote organisaties is het echter vaak niet meteen duidelijk welk team verantwoordelijk is voor een specifieke fout. Het zoeken naar het juiste team kan daardoor tijdrovend en inefficiënt zijn, wat leidt tot onnodig hoge kosten en verspilling van middelen.

Deze bachelorproef onderzoekt hoe grote organisaties hun support op een efficiëntere manier kunnen bewerkstelligen door middel van een virtuele assistent. Deze virtuele assistent kan hierbij een ondersteunende rol spelen voor medewerkers, die verantwoordelijk zijn voor het afhandelen van support. Deze chatbot kan antwoorden geven op veelvoorkomende vragen, of de medewerkers doorverwijzen naar relevante documentatie en contactpersonen. Zo fungeert de virtuele assistent als hulpmiddel voor supportmedewerkers, waardoor zij sneller en efficiënter kunnen werken. Dit leidt tot een hogere klanttevredenheid, een snellere afhandeling van supporttickets en mogelijke kostenbesparingen binnen de organisatie.

In dit onderzoek richten wordt gekeken hoe IT-teams binnen FOD Financiën de supporttickets moeten afhandelen. Om het proces te verbeteren, is het van belang om een helder beeld te krijgen van de huidige manier waarop supporttickets worden afgehandeld. Dit begint met een grondige analyse van het bestaande proces, waarbij we in kaart brengen waar de knelpunten zich bevinden en waarom deze problemen optreden.

Op basis van deze analyse wordt een duidelijk overzicht gevormd van de zwakke punten in het proces, waarna mogelijke oplossingen kunnen worden onderzocht. Concreet wordt gekeken hoe een Large Language Model (LLM) het proces kan versnellen of efficiënter kan maken. Hiervoor worden verschillende opties voor LLM’s geëvalueerd, waarbij we rekening houden met de functionaliteiten die het model moet bieden en met de financiële en praktische beperkingen.

Als onderdeel van dit onderzoek wordt een PoC ontwikkeld. Deze PoC kan vervolgens worden getest door de betrokken medewerkers, zodat we kunnen beoordelen of het voorgestelde model daadwerkelijk bijdraagt aan een efficiëntere afhandeling van supporttickets. Samengevat zullen tijdens de literatuurstudie de volgende zaken worden onderzocht. Dit zijn, met andere woorden, de deelvragen van het probleemdomein:

\begin{itemize} 
    \item Welke bestaande LLM-modellen kunnen worden gebruikt voor het ontwikkelen van een Retrieval-Augmented Generation (RAG)? 
    \item Wat zijn de belangrijkste voor- en nadelen van deze modellen? 
    \item Welke bestaande tools en frameworks kunnen bijdragen aan het opzetten van een RAG? 
    \item Wat houdt de AI Act in, en wat zijn de belangrijkste richtlijnen die hierin moeten worden gevolgd? 
    \item Wat zijn de bestaande best practices voor de organisatie van IT-supportprocessen? 
\end{itemize}

De antwoorden op deze vragen zullen worden vastgelegd in de literatuurstudie, die als basis zal dienen voor de ontwikkeling van de PoC. Binnen de PoC moeten de vragen van het oplossingsdomein worden beantwoord. Concreet is het de bedoeling om de volgende vragen te adresseren:

\begin{itemize} 
    \item Welke LLM-modellen sluiten het beste aan bij de gestelde requirements voor het ontwikkelen van een virtuele supportassistent? 
    \item Welke LLM-modellen presteren het best voor deze specifieke usecase? 
    \item Welke stappen moeten worden genomen om bij de ontwikkeling van een RAG te voldoen aan het wettelijke kader van de AI Act? 
\end{itemize}

%---------- Stand van zaken ---------------------------------------------------

\section{Stand van zaken}%
\label{sec:stand van zaken}

In een sterk veranderende omgeving wordt het steeds uitdagender om snel en adequaat incidenten te beheren en klantvragen te beantwoorden. Dit wordt veroorzaakt door factoren zoals de snel evoluerende IT-omgeving en de toenemende complexiteit van IT-infrastructuren. Deze ontwikkelingen leiden tot een groei van diverse en complexe incidenten, die vaak moeilijk binnen het incidentmanagementproces kunnen worden opgelost. Hierdoor worden vragen van de eerstelijnsmedewerkers regelmatig doorgestuurd naar meer gespecialiseerde IT-teams. Hoewel dit begrijpelijk is, resulteert het in hogere kosten en een toename van klantontevredenheid \autocite{Schmidt2024}.

Om hier een antwoord op te bieden kan gekeken worden naar de opkomst van ChatGPT en andere Large Language Models (LLM). Deze hebben de mogelijkheid om generatieve informatieverzameling te vergroten. Dit roept de vraag op of dergelijke systemen binnen een organisatie effectief kunnen worden ingezet en welke factoren daarbij moeten worden overwogen.

Naast het bekende GPT-4 zijn er ook diverse open-source modellen, zoals Llama 2, StableBeluga2 en Mixtral 8x7B. Hoewel deze modellen over het algemeen iets minder krachtig zijn dan GPT-4, bieden ze belangrijke voordelen op het gebied van dataveiligheid en privacy. Bovendien kunnen open-source modellen eenvoudiger worden aangepast en gepersonaliseerd om beter aan te sluiten op de specifieke behoeften van de gebruiker \autocite{KernanFreire2024}.

Hoewel het ontwikkelen van een eigen gepersonaliseerde LLM wellicht als een luxeprobleem kan lijken, kan dit in sommige organisaties cruciaal zijn. Het is dan ook belangrijk om niet alleen te kijken naar de prestaties van een model, maar ook naar de mate waarin het kan worden aangepast aan de specifieke vereisten van de organisatie. Uit het onderzoek van \textcite{Topsakal2023} blijkt dat er veel mogelijkheden zijn om zelf LLM-gebaseerde modellen op te zetten. In dit onderzoek werd gebruikgemaakt van LangChain, een open-source framework dat specifiek is ontwikkeld om het bouwen van LLM-toepassingen te vergemakkelijken.

\textcite{Topsakal2023} onderzochten de diverse functionaliteiten van LangChain, waaronder de optie om vragen te beantwoorden op basis van documenten. In dit proces wordt de LLM getraind met de verstrekte documenten, zodat een gebruiker vragen kan stellen over deze documenten en zo snel extra kennis kan opdoen. LangChain ondersteunt een breed scala aan documenttypen, zoals CSV, PDF, HTML, JSON, Excel, GitHub, Google Drive, OneDrive en XML.

Dit onderzoek toont aan dat er mogelijkheden zijn om LLM-toepassingen te ontwikkelen voor specifieke doeleinden. LangChain is hier een voorbeeld van. Voor de verdere literatuurstudie zal aanvullend onderzoek worden gedaan naar alternatieve frameworks en hun specifieke voor- en nadelen. Dit stelt ons in staat een weloverwogen keuze te maken voor het meest geschikte framework, afgestemd op de specifieke use case. Frameworks zoals Hugging Face en Haystack kunnen daarbij als waardevolle alternatieven worden overwogen.

% Voor literatuurverwijzingen zijn er twee belangrijke commando's:
% \autocite{KEY} => (Auteur, jaartal) Gebruik dit als de naam van de auteur
%   geen onderdeel is van de zin.
% \textcite{KEY} => Auteur (jaartal)  Gebruik dit als de auteursnaam wel een
%   functie heeft in de zin (bv. ``Uit onderzoek door Doll & Hill (1954) bleek
%   ...'')

%---------- Methodologie ------------------------------------------------------
\section{Methodologie}%
\label{sec:methodologie}

Voor de opstart van deze bachelorproef is een uitgebreide literatuurstudie essentieel om de bestaande mogelijkheden op het gebied van virtuele assistenten te verkennen. Deze studie richt zich op een vergelijkende analyse die inzicht biedt in de verschillende beschikbare opties voor het ontwikkelen van een virtuele supportassistent. Hierbij worden de voor- en nadelen van elke optie in kaart gebracht, zodat op basis van deze informatie een onderbouwde keuze kan worden gemaakt voor de uitwerking van een PoC. De literatuurstudie moet ook duidelijkheid verschaffen over de benodigde hardware- en softwarevereisten voor de ontwikkeling.

Gekoppeld aan de literatuurstudie zullen interviews worden afgenomen. Het doel van deze interviews is om een helder overzicht te verkrijgen van de verschillende vereisten voor de virtuele assistent. Op basis van het overzicht uit de literatuurstudie kan vervolgens een meer gerichte selectie worden gemaakt van de verschillende opties. Het uiteindelijke doel is om voor twee à drie modellen een PoC uit te werken die verder getest kunnen worden. Het is met andere woorden van belang om de verschillende modellen zo uitgebreid mogelijk te onderzoeken, zodat zoveel mogelijk modellen getoetst kunnen worden aan de gevraagde vereisten.Eens de literatuurstudie is afgerond en de interviews zijn afgenomen, kan met behulp van een MoSCoW-analyse een rangschikking worden opgesteld van de verschillende beschikbare modellen. Deze rangschikking bepaalt welke modellen worden geselecteerd voor het uitwerken van een PoC.

Elk van de geselecteerde modellen wordt vervolgens uitgewerkt in een PoC. Zodra de verschillende PoC’s beschikbaar zijn, wordt een vergelijking gemaakt tussen de modellen. Hierbij worden de volgende aspecten specifiek getest:

\begin{itemize} 
    \item Wat is de kwaliteit van de antwoorden? 
    \item Wat is de tijd en de kost van een query?
    \item Hoe eenvoudig is het om het model op te zetten? 
\end{itemize}

De kwaliteit van de antwoorden zal worden gemeten aan de hand van de ROUGE-score, terwijl de tijd per query gemeten en vergeleken zal worden per model. Gezien het derde criterium eerder subjectief is, zal dit minder doorwegen in de uiteindelijke vergelijking. Aan de hand van deze drie criteria zal uiteindelijk een vergelijking worden gemaakt, waaruit zal blijken welk model het beste voldoet aan de gevraagde functionaliteit. Zo kan aan het einde van het onderzoek worden bepaald welke van de verschillende PoC's de meeste troeven heeft om in de praktijk te worden gebruikt.


%---------- Verwachte resultaten ----------------------------------------------
\section{Verwacht resultaat, conclusie}%
\label{sec:verwachte_resultaten}

Het verwachte resultaat van deze bachelorproef is zoals reeds vermeld tweeledig. Enerzijds wordt er een vergelijkende studie opgesteld, die voor bedrijven kan dienen als leidraad bij de implementatie van virtuele support assistenten en hen inzicht biedt in de verschillende mogelijkheden. Het is daarbij essentieel dat de vergelijkende studie niet alleen de technische aspecten behandelt, maar ook de juridische factoren in kaart brengt.

Anderzijds zullen een aantal modellen uitgewerkt worden in een PoC. Hiermee wordt de vergelijkende studie praktisch toegepast en vormt het een voorbeeld voor organisaties die een soortgelijk project willen realiseren.

Bedrijven die te maken hebben met uitdagingen op het gebied van support kunnen deze vergelijkende studie benutten om te bepalen welke oplossing het beste bij hun behoeften past. Bovendien bieden de PoC's, indien relevant en toepasbaar, de mogelijkheid om als basis te dienen voor een eigen implementatie, waarbij aanpassingen kunnen worden gemaakt om deze optimaal af te stemmen op de specifieke bedrijfscontext. Indien één van de PoC's voldoende functioneel blijkt, kan deze een meerwaarde vormen door een snellere afhandeling van vragen die klanten hebben. Dit leidt op zijn beurt naar een hogere klantentevredenheid. 

Het uiteindelijke onderzoeksresultaat zal een op ChatGPT lijkende interface opleveren, waarmee gebruikers gerichte antwoorden kunnen krijgen op vragen die specifiek betrekking hebben op supportvragen die de organisatie krijgt van klanten. Deze oplossing richt zich dus op een bedrijfsspecifieke virtuele support assistent, die getraind is op basis van de interne documentatie van een organisatie en binnen die context wordt ingezet.


