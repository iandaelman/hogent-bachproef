%---------- Inleiding ---------------------------------------------------------

\section{Inleiding}%
\label{sec:inleiding}

Een ontwikkelingsteam heeft uiteenlopende verantwoordelijkheden. Naast hun kernactiviteit, het ontwikkelen van software, is het ook belangrijk dat zij ondersteuning bieden bij vragen en problemen van klanten. Deze vragen hebben vaak betrekking op fouten of problemen binnen de toepassing. In grote organisaties is het echter vaak niet meteen duidelijk welk team verantwoordelijk is voor een specifieke fout. Het zoeken naar het juiste team kan daardoor tijdrovend en inefficiënt zijn, wat leidt tot onnodig hoge kosten en verspilling van middelen.

Dit onderzoek richt zich op grote organisaties waar efficiënte support essentieel is om klantvragen snel en accuraat af te handelen. Een virtuele assistent kan hierbij een ondersteunende rol spelen door medewerkers, die verantwoordelijk zijn voor het afhandelen van support, te voorzien van een chatbot. Deze chatbot kan antwoorden geven op veelvoorkomende vragen, of de medewerkers doorverwijzen naar relevante documentatie en contactpersonen. Zo fungeert de virtuele assistent als hulpmiddel voor supportmedewerkers, waardoor zij sneller en efficiënter kunnen werken. Dit leidt tot een hogere klanttevredenheid, een snellere afhandeling van supporttickets en mogelijke kostenbesparingen binnen de organisatie.

In dit onderzoek richten we ons specifiek op de supporttickets die IT-teams binnen FOD Financiën moeten afhandelen. Om het proces te verbeteren, is het van belang om een helder beeld te krijgen van de huidige manier waarop supporttickets worden afgehandeld. Dit begint met een grondige analyse van het bestaande proces, waarbij we in kaart brengen waar de knelpunten zich bevinden en waarom deze problemen optreden.

Op basis van deze analyse wordt een duidelijk overzicht gevormd van de zwakke punten in het proces, waarna mogelijke oplossingen kunnen worden onderzocht. Concreet wordt gekeken hoe een Large Language Model (LLM) het proces kan versnellen of efficiënter kan maken. Hiervoor worden verschillende opties voor LLM’s geëvalueerd, waarbij we rekening houden met de functionaliteiten die het model moet bieden en met de financiële en praktische beperkingen.

Als onderdeel van dit onderzoek wordt een Proof of Concept (PoC) ontwikkeld. Deze PoC kan vervolgens worden getest door de betrokken medewerkers, zodat we kunnen beoordelen of het voorgestelde model daadwerkelijk bijdraagt aan een efficiëntere afhandeling van supporttickets.

%---------- Stand van zaken ---------------------------------------------------

\section{Stand van zaken}%
\label{sec:stand van zaken}

In een sterk veranderende omgeving wordt het steeds uitdagender om snel en adequaat incidenten te beheren en klantvragen te beantwoorden. Dit wordt veroorzaakt door factoren zoals de snel evoluerende IT-omgeving en de toenemende complexiteit van IT-infrastructuren. Deze ontwikkelingen leiden tot een groei van diverse en complexe incidenten, die vaak moeilijk binnen het incidentmanagementproces kunnen worden opgelost. Hierdoor worden vragen van de eerstelijnsmedewerkers regelmatig doorgestuurd naar meer gespecialiseerde IT-teams. Hoewel dit begrijpelijk is, resulteert het in hogere kosten en een toename van klantontevredenheid \autocite{Schmidt2024}.

Om hier een antwoord op te bieden kan gekeken worden naar de opkomst van ChatGPT en andere Large Language Models (LLM). Deze hebben de mogelijkheid om generatieve informatieverzameling te vergroten. Dit roept de vraag op of dergelijke systemen binnen een organisatie effectief kunnen worden ingezet en welke factoren daarbij moeten worden overwogen.

Naast het bekende GPT-4 zijn er ook diverse open-source modellen, zoals Llama 2, StableBeluga2 en Mixtral 8x7B. Hoewel deze modellen over het algemeen iets minder krachtig zijn dan GPT-4, bieden ze belangrijke voordelen op het gebied van dataveiligheid en privacy. Bovendien kunnen open-source modellen eenvoudiger worden aangepast en gepersonaliseerd om beter aan te sluiten op de specifieke behoeften van de gebruiker \autocite{KernanFreire2024}.

Hoewel het ontwikkelen van een eigen gepersonaliseerde LLM wellicht als een luxeprobleem kan lijken, kan dit in sommige organisaties cruciaal zijn. Het is dan ook belangrijk om niet alleen te kijken naar de prestaties van een model, maar ook naar de mate waarin het kan worden aangepast aan de specifieke vereisten van de organisatie.

Uit het onderzoek van \textcite{Topsakal2023} blijkt dat er veel mogelijkheden zijn om zelf LLM-gebaseerde modellen op te zetten. In dit onderzoek wordt gebruikgemaakt van LangChain, een open-source framework dat specifiek is ontwikkeld om het bouwen van LLM-toepassingen te vergemakkelijken.

\textcite{Topsakal2023} onderzochten de diverse functionaliteiten van LangChain, waaronder de optie om vragen te beantwoorden op basis van documenten. In dit proces wordt de LLM getraind met de verstrekte documenten, zodat een gebruiker vragen kan stellen over deze documenten en zo snel extra kennis kan opdoen. LangChain ondersteunt een breed scala aan documenttypen, zoals CSV, PDF, HTML, JSON, Excel, GitHub, Google Drive, OneDrive en XML.

Hoewel LangChain als open-source framework veel mogelijkheden biedt, is het verstandig om verder onderzoek te doen naar alternatieve frameworks en hun specifieke voor- en nadelen. Dit maakt het mogelijk om een weloverwogen keuze te maken voor het meest geschikte framework, afgestemd op de specifieke use case. Frameworks zoals Hugging Face en Haystack kunnen hierbij als waardevolle alternatieven worden overwogen.

% Voor literatuurverwijzingen zijn er twee belangrijke commando's:
% \autocite{KEY} => (Auteur, jaartal) Gebruik dit als de naam van de auteur
%   geen onderdeel is van de zin.
% \textcite{KEY} => Auteur (jaartal)  Gebruik dit als de auteursnaam wel een
%   functie heeft in de zin (bv. ``Uit onderzoek door Doll & Hill (1954) bleek
%   ...'')

%---------- Methodologie ------------------------------------------------------
\section{Methodologie}%
\label{sec:methodologie}

Voor de opstart van deze bachelorproef is een uitgebreide literatuurstudie essentieel om de bestaande mogelijkheden op het gebied van virtuele assistenten te verkennen. Deze studie richt zich op een vergelijkende analyse die inzicht biedt in de verschillende beschikbare opties voor het ontwikkelen van een virtuele supportassistent. Hierbij worden de voor- en nadelen van elke optie in kaart gebracht, zodat op basis van deze informatie een onderbouwde keuze kan worden gemaakt voor de uitwerking van een proof of concept. De literatuurstudie moet ook duidelijkheid verschaffen over de benodigde hardware- en softwarevereisten voor de ontwikkeling.

Een eerste verkenning binnen de literatuurstudie richt zich op open-source softwareoplossingen voor de ontwikkeling van een LLM-gebaseerde applicatie. LangChain is hierbij een interessante optie, maar het is van cruciaal belang om ook andere alternatieven te onderzoeken. Voor versiebeheer en samenwerking tijdens de ontwikkeling is het gebruik van een GitHub-repository noodzakelijk.

Het uiteindelijke framework dat gekozen wordt, zal afhankelijk zijn van de specifieke noden en eisen. Deze worden in kaart gebracht door middel van een interview met de betrokken partijen. Tijdens dit proces kunnen de partijen duidelijk aangeven welke functionaliteiten essentieel zijn en welke minder prioriteit hebben. De keuze voor een framework en de selectie van de benodigde tools zullen gebaseerd zijn op de inzichten die door de promotor worden verschaft. Deze inzichten worden eveneens verzameld via een interview.

Binnen de bachelorproef zijn zowel de vergelijkende studie als de proof of concept van cruciaal belang. Om beide onderdelen voldoende aandacht te geven, wordt de beschikbare tijd gelijkmatig verdeeld. De vergelijkende studie krijgt twee maanden om tot een gedegen resultaat te komen, terwijl ook twee maanden worden gereserveerd voor de ontwikkeling van de proof of concept. Het is mogelijk dat ideeën voor de proof of concept al tijdens de vergelijkende studie ontstaan, of dat de vergelijkende studie nog wordt aangepast tijdens de ontwikkeling. Desondanks is het doel om eerst een solide basis te leggen met de vergelijkende studie, die dient als fundament voor de verdere uitwerking van de proof of concept.

Het uiteindelijke resultaat is een virtuele assistent die medewerkers ondersteunt bij het afhandelen van supporttickets. In eerste instantie zal deze tool als proefproject worden getest door een IT-team. De resultaten van deze test zullen worden geanalyseerd en opgenomen in de bachelorproef. Bij een succesvolle test kan een bredere implementatie worden overwogen, al valt dit waarschijnlijk buiten de scope van deze bachelorproef.


%---------- Verwachte resultaten ----------------------------------------------
\section{Verwacht resultaat, conclusie}%
\label{sec:verwachte_resultaten}

Het verwachte resultaat van deze bachelorproef is tweeledig. Enerzijds wordt er een vergelijkende studie opgesteld, die voor bedrijven kan dienen als leidraad bij de implementatie van virtuele support assistenten en hen inzicht biedt in de verschillende mogelijkheden. Het is daarbij essentieel dat de vergelijkende studie niet alleen de technische aspecten behandelt, maar ook de financiële en juridische factoren in kaart brengt.

Anderzijds zal een proof of concept worden ontwikkeld als illustratie van één van de mogelijke opties binnen dit domein. Hiermee wordt de vergelijkende studie praktisch toegepast en vormt het een voorbeeld voor personen of organisaties die een soortgelijk project willen realiseren.

Bedrijven die te maken hebben met uitdagingen op het gebied van support kunnen deze vergelijkende studie benutten om te bepalen welke oplossing het beste bij hun behoeften past. Bovendien biedt de proof of concept, indien relevant en toepasbaar, de mogelijkheid om als basis te dienen voor een eigen implementatie, waarbij aanpassingen kunnen worden gemaakt om deze optimaal af te stemmen op de specifieke bedrijfscontext. Indien de proof of concept voldoende functioneel blijkt, kan deze een meerwaarde vormen door een snellere afhandeling van vragen die klanten hebben. Dit leidt op zijn beurt naar een hogeren klantentevredenheid. 

Het uiteindelijke onderzoeksresultaat zal een op ChatGPT lijkende interface opleveren, waarmee gebruikers gerichte antwoorden kunnen krijgen op vragen die specifiek betrekking hebben op support vragen die hun organisatie krijgt van klanten. Deze oplossing richt zich dus op een bedrijfsspecifieke virtuele support assistent, die getraind is op basis van de interne documentatie van een organisatie en binnen die context wordt ingezet.


