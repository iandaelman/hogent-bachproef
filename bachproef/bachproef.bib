% Encoding: UTF-8

@InProceedings{Wang2024,
  author    = {Wang, Xiaohua and Wang, Zhenghua and Gao, Xuan and Zhang, Feiran and Wu, Yixin and Xu, Zhibo and Shi, Tianyuan and Wang, Zhengyuan and Li, Shizheng and Qian, Qi and Yin, Ruicheng and Lv, Changze and Zheng, Xiaoqing and Huang, Xuanjing},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  title     = {Searching for Best Practices in Retrieval-Augmented Generation},
  doi       = {10.18653/v1/2024.emnlp-main.981},
  editor    = {Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung},
  pages     = {17716--17736},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.emnlp-main.981/},
  abstract  = {Retrieval-augmented generation (RAG) techniques have proven to be effective in integrating up-to-date information, mitigating hallucinations, and enhancing response quality, particularly in specialized domains. While many RAG approaches have been proposed to enhance large language models through query-dependent retrievals, these approaches still suffer from their complex implementation and prolonged response times. Typically, a RAG workflow involves multiple processing steps, each of which can be executed in various ways. Here, we investigate existing RAG approaches and their potential combinations to identify optimal RAG practices. Through extensive experiments, we suggest several strategies for deploying RAG that balance both performance and efficiency. Moreover, we demonstrate that multimodal retrieval techniques can significantly enhance question-answering capabilities about visual inputs and accelerate the generation of multimodal content using a {\textquotedblleft}retrieval as generation{\textquotedblright} strategy.},
  address   = {Miami, Florida, USA},
  month     = nov,
  year      = {2024},
}

@Article{Gao2023,
  author  = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  title   = {Retrieval-augmented generation for large language models: A survey},
  journal = {arXiv preprint arXiv:2312.10997},
  year    = {2023},
}

@Misc{Akkiraju2024,
  author        = {Rama Akkiraju and Anbang Xu and Deepak Bora and Tan Yu and Lu An and Vishal Seth and Aaditya Shukla and Pritam Gundecha and Hridhay Mehta and Ashwin Jha and Prithvi Raj and Abhinav Balasubramanian and Murali Maram and Guru Muthusamy and Shivakesh Reddy Annepally and Sidney Knowles and Min Du and Nick Burnett and Sean Javiya and Ashok Marannan and Mamta Kumari and Surbhi Jha and Ethan Dereszenski and Anupam Chakraborty and Subhash Ranjan and Amina Terfai and Anoop Surya and Tracey Mercer and Vinodh Kumar Thanigachalam and Tamar Bar and Sanjana Krishnan and Samy Kilaru and Jasmine Jaksic and Nave Algarici and Jacob Liberman and Joey Conway and Sonu Nayyar and Justin Boitano},
  title         = {FACTS About Building Retrieval Augmented Generation-based Chatbots},
  eprint        = {2407.07858},
  url           = {https://arxiv.org/abs/2407.07858},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  year          = {2024},
}

@InBook{Yu2025,
  author    = {Yu, Hao and Gan, Aoran and Zhang, Kai and Tong, Shiwei and Liu, Qi and Liu, Zhaofeng},
  booktitle = {Big Data},
  date      = {2025},
  title     = {Evaluation ofÂ Retrieval-Augmented Generation: A Survey},
  doi       = {10.1007/978-981-96-1024-2_8},
  isbn      = {9789819610242},
  pages     = {102--120},
  publisher = {Springer Nature Singapore},
  issn      = {1865-0937},
}

@Misc{Xu2023,
  author    = {Xu, Peng and Ping, Wei and Wu, Xianchao and McAfee, Lawrence and Zhu, Chen and Liu, Zihan and Subramanian, Sandeep and Bakhturina, Evelina and Shoeybi, Mohammad and Catanzaro, Bryan},
  date      = {2023},
  title     = {Retrieval meets Long Context Large Language Models},
  doi       = {10.48550/ARXIV.2310.03025},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Information Retrieval (cs.IR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{white2024livebenchchallengingcontaminationfreellm,
  author        = {Colin White and Samuel Dooley and Manley Roberts and Arka Pal and Ben Feuer and Siddhartha Jain and Ravid Shwartz-Ziv and Neel Jain and Khalid Saifullah and Siddartha Naidu and Chinmay Hegde and Yann LeCun and Tom Goldstein and Willie Neiswanger and Micah Goldblum},
  title         = {LiveBench: A Challenging, Contamination-Free LLM Benchmark},
  eprint        = {2406.19314},
  url           = {https://arxiv.org/abs/2406.19314},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  year          = {2024},
}

@Misc{chiang2024chatbot,
  author        = {Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Hao Zhang and Banghua Zhu and Michael Jordan and Joseph E. Gonzalez and Ion Stoica},
  title         = {Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference},
  eprint        = {2403.04132},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  year          = {2024},
}

@Comment{jabref-meta: databaseType:biblatex;}
