% Encoding: UTF-8

@Misc{Akkiraju2024,
  author        = {Rama Akkiraju and Anbang Xu and Deepak Bora and Tan Yu and Lu An and Vishal Seth and Aaditya Shukla and Pritam Gundecha and Hridhay Mehta and Ashwin Jha and Prithvi Raj and Abhinav Balasubramanian and Murali Maram and Guru Muthusamy and Shivakesh Reddy Annepally and Sidney Knowles and Min Du and Nick Burnett and Sean Javiya and Ashok Marannan and Mamta Kumari and Surbhi Jha and Ethan Dereszenski and Anupam Chakraborty and Subhash Ranjan and Amina Terfai and Anoop Surya and Tracey Mercer and Vinodh Kumar Thanigachalam and Tamar Bar and Sanjana Krishnan and Samy Kilaru and Jasmine Jaksic and Nave Algarici and Jacob Liberman and Joey Conway and Sonu Nayyar and Justin Boitano},
  title         = {FACTS About Building Retrieval Augmented Generation-based Chatbots},
  eprint        = {2407.07858},
  url           = {https://arxiv.org/abs/2407.07858},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  year          = {2024},
}

@InBook{Yu2025,
  author    = {Yu, Hao and Gan, Aoran and Zhang, Kai and Tong, Shiwei and Liu, Qi and Liu, Zhaofeng},
  booktitle = {Big Data},
  date      = {2025},
  title     = {Evaluation of Retrieval-Augmented Generation: A Survey},
  doi       = {10.1007/978-981-96-1024-2_8},
  isbn      = {9789819610242},
  pages     = {102--120},
  publisher = {Springer Nature Singapore},
  issn      = {1865-0937},
}

@Misc{Xu2023,
  author    = {Xu, Peng and Ping, Wei and Wu, Xianchao and McAfee, Lawrence and Zhu, Chen and Liu, Zihan and Subramanian, Sandeep and Bakhturina, Evelina and Shoeybi, Mohammad and Catanzaro, Bryan},
  date      = {2023},
  title     = {Retrieval meets Long Context Large Language Models},
  doi       = {10.48550/ARXIV.2310.03025},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Information Retrieval (cs.IR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{white2024livebenchchallengingcontaminationfreellm,
  author        = {Colin White and Samuel Dooley and Manley Roberts and Arka Pal and Ben Feuer and Siddhartha Jain and Ravid Shwartz-Ziv and Neel Jain and Khalid Saifullah and Siddartha Naidu and Chinmay Hegde and Yann LeCun and Tom Goldstein and Willie Neiswanger and Micah Goldblum},
  title         = {LiveBench: A Challenging, Contamination-Free LLM Benchmark},
  eprint        = {2406.19314},
  url           = {https://arxiv.org/abs/2406.19314},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  year          = {2024},
}

@Misc{Zhao2024,
  author    = {Zhao, Penghao and Zhang, Hailin and Yu, Qinhan and Wang, Zhengren and Geng, Yunteng and Fu, Fangcheng and Yang, Ling and Zhang, Wentao and Jiang, Jie and Cui, Bin},
  date      = {2024},
  title     = {Retrieval-Augmented Generation for AI-Generated Content: A Survey},
  doi       = {10.48550/ARXIV.2402.19473},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{Chiang2024,
  author    = {Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhang, Hao and Zhu, Banghua and Jordan, Michael and Gonzalez, Joseph E. and Stoica, Ion},
  date      = {2024},
  title     = {Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference},
  doi       = {10.48550/ARXIV.2403.04132},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{Wang2024,
  author    = {Wang, Xiaohua and Wang, Zhenghua and Gao, Xuan and Zhang, Feiran and Wu, Yixin and Xu, Zhibo and Shi, Tianyuan and Wang, Zhengyuan and Li, Shizheng and Qian, Qi and Yin, Ruicheng and Lv, Changze and Zheng, Xiaoqing and Huang, Xuanjing},
  date      = {2024},
  title     = {Searching for Best Practices in Retrieval-Augmented Generation},
  doi       = {10.48550/ARXIV.2407.01219},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{Gao2023,
  author    = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
  date      = {2023},
  title     = {Retrieval-Augmented Generation for Large Language Models: A Survey},
  doi       = {10.48550/ARXIV.2312.10997},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{Wu2024,
  author    = {Wu, Shangyu and Xiong, Ying and Cui, Yufei and Wu, Haolun and Chen, Can and Yuan, Ye and Huang, Lianming and Liu, Xue and Kuo, Tei-Wei and Guan, Nan and Xue, Chun Jason},
  date      = {2024},
  title     = {Retrieval-Augmented Generation for Natural Language Processing: A Survey},
  doi       = {10.48550/ARXIV.2407.13193},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{LiveBench2025,
  author = {{LiveBench AI}},
  title  = {LiveBench ranking van verschillende LLMs},
  note   = {Geraadpleegd op 16 februari 2025},
  url    = {https://livebench.ai/#/details},
  year   = {2025},
}

@Misc{Vaswani2017,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date      = {2017},
  title     = {Attention Is All You Need},
  doi       = {10.48550/ARXIV.1706.03762},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@InBook{Gupta2025,
  author    = {Gupta, Rajan and Tiwari, Sanju and Chaudhary, Poonam},
  booktitle = {Generative AI: Techniques, Models and Applications},
  date      = {2025},
  title     = {Large Language Models},
  doi       = {10.1007/978-3-031-82062-5_5},
  isbn      = {978-3-031-82062-5},
  location  = {Cham},
  pages     = {81--102},
  publisher = {Springer Nature Switzerland},
  url       = {https://doi.org/10.1007/978-3-031-82062-5_5},
  abstract  = {Large Language Models have presented an impressive performance and have become fundamental in real-world applications. These models are built upon vast amounts of text data and are trained to understand, generate, and manipulate human language with remarkable fluency. Large language models have applications in various fields, including content generation, language translation, sentiment analysis, and conversational agents. These models are based on neural networks and considered as pre-trained, large-scale, statistical language models. LLMs are playing a significant role in advancement of AI agents. This chapter has explored different existing surveys and summarized in two categories, 7 general survey papers and 15 domain specific survey papers. Primary focus of chapter is to explore the types of large language models, tasks of LLMs, frame-works, applications and challenges.},
}

@Misc{Ganesan2018,
  author    = {Ganesan, Kavita},
  date      = {2018},
  title     = {ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization Tasks},
  doi       = {10.48550/ARXIV.1803.01937},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Information Retrieval (cs.IR), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@InProceedings{papineni-etal-2002-bleu,
  author    = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle = {Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics},
  title     = {{B}leu: a Method for Automatic Evaluation of Machine Translation},
  doi       = {10.3115/1073083.1073135},
  editor    = {Isabelle, Pierre and Charniak, Eugene and Lin, Dekang},
  pages     = {311--318},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P02-1040/},
  address   = {Philadelphia, Pennsylvania, USA},
  month     = jul,
  year      = {2002},
}

@Misc{microsoft2024evaluation,
  author = {{Microsoft Corporation}},
  title  = {List of evaluation metrics for LLMs — Reference-based metrics},
  note   = {Geraadpleegd op 21 april 2025},
  url    = {https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/evaluation/list-of-eval-metrics#reference-based-metrics},
  year   = {2024},
}

@Comment{jabref-meta: databaseType:biblatex;}
